{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/2544771149.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  title_basics_df = pd.read_csv('datasets/title.basics.tsv', delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "title_basics_df = pd.read_csv('datasets/title.basics.tsv', delimiter='\\t')\n",
    "ratings_df = pd.read_csv('datasets/ml-1m/ratings.dat', delimiter='::', engine='python', header=None, names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "ratings_df.set_index('userId', inplace=True)\n",
    "users_df = pd.read_csv('datasets/ml-1m/users.dat', delimiter='::', engine='python', header=None, names=['userId', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "users_df.set_index('userId', inplace=True)\n",
    "movies_df = pd.read_csv('datasets/ml-1m/movies.dat', delimiter='::', engine='python', header=None, names=['movieId', 'title', 'genres'], encoding=\"ISO-8859-1\")\n",
    "movies_df.set_index('movieId', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize text data (lower case, remove -, accents...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def reformat_movie_title_movielens(df, column='title'):\n",
    "    ''' \n",
    "    Reformat the movie title to match the movielens dataset \n",
    "        - Remove the year from the title\n",
    "        - Remove any - or : from the title\n",
    "        - Remove all accent characters\n",
    "        - Normalize the title to lowercase\n",
    "    '''\n",
    "    df[column] = df[column].astype(str)\n",
    "    # Strip year and extra whitespace\n",
    "    if column == 'title':\n",
    "        df[column] = df[column].str.extract(r'^(.*?)\\s*\\(')[0]\n",
    "    # Remove hyphens, colons\n",
    "    df[column] = df[column].replace({'-': '', ':': ''}, regex=True)\n",
    "    # Remove accent characters\n",
    "    df[column] = df[column].apply(unidecode)\n",
    "    # Convert to lowercase\n",
    "    df[column] = df[column].str.lower()\n",
    "    # Trim any leading or trailing whitespace\n",
    "    df[column] = df[column].str.strip()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = reformat_movie_title_movielens(movies_df, column='title')\n",
    "movies_df['movieId'] = movies_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "We merge the data from imdb and movielens using the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_df.drop(title_basics_df[title_basics_df['titleType'] != 'movie'].index, inplace=True)\n",
    "title_basics_df.drop(columns=['titleType'], inplace=True)\n",
    "title_basics_df.dropna(subset=['primaryTitle'], inplace=True)\n",
    "title_basics_df = reformat_movie_title_movielens(title_basics_df, column='primaryTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge the movies_df with the merged_imdb_df, if the title matches, we expect to have at maximum len(movies_df) rows\n",
    "movies_merged_df = pd.merge(movies_df, title_basics_df, left_on='title', right_on='primaryTitle', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniformize the genres, we transform genre in a Python List format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_x is in this format \"Action|Adventure|Sci-Fi\" genre_y is in this format \"Action,Adventure,Sci-Fi\" we need to see if the genres in x are in y if not we drop the row\n",
    "movies_merged_df['genres_x'] = movies_merged_df['genres_x'].str.replace('|', ',')\n",
    "movies_merged_df['genres_x'] = movies_merged_df['genres_x'].astype(str).str.lower()\n",
    "movies_merged_df['genres_y'] = movies_merged_df['genres_y'].str.lower()\n",
    "movies_merged_df['genres_x'] = movies_merged_df['genres_x'].str.split(',')\n",
    "movies_merged_df['genres_y'] = movies_merged_df['genres_y'].str.split(',')\n",
    "# We should check if at least one of the genre in x is in y if not we drop the row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_genre(genres_x, genres_y):\n",
    "    for genre in genres_x:\n",
    "        if genre in genres_y:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "movies_merged_df['genre_match'] = movies_merged_df.apply(lambda x: check_genre(x['genres_x'], x['genres_y']), axis=1)\n",
    "movies_merged_df = movies_merged_df[movies_merged_df['genre_match']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some case, we happen to have movies with the same title and genres but a different start year. We decide to drop the duplicates and only keep the most recent one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/2130497013.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df.drop(columns=['genres_x', 'genre_match', 'primaryTitle', 'tconst'], inplace=True)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/2130497013.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df.rename(columns={'genres_y': 'genres', 'primaryName': 'directors'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows with the same title and genres_x\n",
    "\n",
    "merged_df = movies_merged_df.drop_duplicates(subset=['movieId'])\n",
    "merged_df.drop(columns=['genres_x', 'genre_match', 'primaryTitle', 'tconst'], inplace=True)\n",
    "merged_df.rename(columns={'genres_y': 'genres', 'primaryName': 'directors'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
      "/var/folders/0c/r221n06s23g6gp_ydkg17qcw0000gn/T/ipykernel_18429/3779038764.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df.drop(columns=['genres', 'title', 'originalTitle'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "genres = [\n",
    "    'action',\n",
    "    'adventure',\n",
    "    'animation',\n",
    "    'children',\n",
    "    'comedy',\n",
    "    'crime',\n",
    "    'documentary',\n",
    "    'drama',\n",
    "    'fantasy',\n",
    "    'film-noir',\n",
    "    'horror',\n",
    "    'musical',\n",
    "    'mystery',\n",
    "    'romance',\n",
    "    'sci-Fi',\n",
    "    'thriller',\n",
    "    'war',\n",
    "    'western'\n",
    "]\n",
    "\n",
    "\n",
    "def encode_gender(value):\n",
    "    if value == 'M':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def transform_movies(merged_df):\n",
    "    \"\"\"\n",
    "    This function will transform the merged_df to a format that can be used by the model\n",
    "    1. We will encode the genres as binary values\n",
    "    2. We will drop the title and originalTitle columns since we have the movieId\n",
    "    3. We will replace the '\\\\N' values with 0\n",
    "    4. We will convert the runtimeMinutes and startYear to integers\n",
    "    5. We will add the average rating for each movie\n",
    "    6. We will set the movieId as the index\n",
    "    \"\"\"\n",
    "    for genre in genres:\n",
    "        merged_df[genre] = merged_df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "\n",
    "    merged_df.drop(columns=['genres', 'title', 'originalTitle'], inplace=True)\n",
    "    merged_df.replace('\\\\N', 0, inplace=True)\n",
    "    merged_df['runtimeMinutes'] = merged_df['runtimeMinutes'].astype(int)\n",
    "    merged_df['startYear'] = merged_df['startYear'].astype(int)\n",
    "    # Add the average rating for each movie\n",
    "    average_ratings = ratings_df.groupby('movieId')['rating'].mean().to_dict()\n",
    "    merged_df['average_rating'] = merged_df['movieId'].apply(lambda x: average_ratings.get(x, 0))\n",
    "    movie_features = merged_df.copy()\n",
    "    movie_features.reset_index(inplace=True)\n",
    "    movie_features.drop(columns=['index'], inplace=True)\n",
    "    movie_features.set_index('movieId', inplace=True)\n",
    "    return movie_features\n",
    "\n",
    "def transform_users(user_features, movie_features):\n",
    "    \"\"\"\n",
    "    This function will transform the user_features to a format that can be used by the model\n",
    "    1. We add the average rating given by the user\n",
    "    2. We add the number of ratings given by the user per genre\n",
    "    3. We encode user gender as binary values\n",
    "    4. We encode the zipcode as integers\n",
    "    \"\"\"\n",
    "    # For user features we will add the average rating he gave and the number of ratings he gave per genre\n",
    "    movies_df.drop(columns=['movieId'], inplace=True)\n",
    "    ratings_df = ratings_df.join(movies_df, on='movieId', lsuffix='_ratings', rsuffix='_movies')\n",
    "    ratings_df = ratings_df.join(users_df, on='userId', lsuffix='_ratings', rsuffix='_users')\n",
    "    ratings_df = ratings_df.join(movie_features, on='movieId', lsuffix='_ratings', rsuffix='_features')\n",
    "    user_features['average_rating'] = ratings_df.groupby('userId')['rating'].mean()\n",
    "    user_features['number_of_ratings'] = ratings_df.groupby('userId')['rating'].count()\n",
    "    for genre in genres:\n",
    "        user_features[f'number_of_{genre}_ratings'] = ratings_df.groupby('userId')[genre].sum()\n",
    "\n",
    "    user_features.replace(np.nan, 0, inplace=True)\n",
    "    user_features['gender'] = user_features['gender'].apply(encode_gender)\n",
    "\n",
    "    zipcodes = user_features['zipcode'].unique()\n",
    "    zipcodes_dict = {zipcode: i for i, zipcode in enumerate(zipcodes)}\n",
    "    user_features['zipcode'] = user_features['zipcode'].apply(lambda x: zipcodes_dict[x])\n",
    "    return user_features\n",
    "\n",
    "def interaction_matrix(ratings_df):\n",
    "    \"\"\" \n",
    "    This function will return the interaction matrix Y from the ratings_df\n",
    "    \"\"\"\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(merged_df['movieId'])]\n",
    "    Y = ratings_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "    Y.replace(np.nan, 0, inplace=True)\n",
    "    return Y\n",
    "\n",
    "\n",
    "movie_features = transform_movies(merged_df)\n",
    "user_features = transform_users(users_df, movie_features)\n",
    "Y = interaction_matrix(ratings_df, merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_mappings(ids):\n",
    "    \"\"\"Map original IDs to zero-based indices for array access.\"\"\"\n",
    "    return {old_id: new_index for new_index, old_id in enumerate(ids)}\n",
    "\n",
    "def create_dataset(user_features, movie_features, interaction_matrix):\n",
    "    \"\"\" \n",
    "    This function will create the dataset for the model\n",
    "    We will create the following pairs:\n",
    "    - (user1, user2, movie) with the average rating given by both users\n",
    "    We will use the interaction_matrix to get the users that rated the same movie\n",
    "    User1 id can't be equal to user2 id or higher than user2 id, this way we ensure that we don't have duplicate pairs\n",
    "    We can create every combination of pairs with the users that rated the same movie however this will create a lot of pairs (O(n^2))\n",
    "    \"\"\"\n",
    "    user1_vecs, user2_vecs, movie_vecs, ratings = [], [], [], []\n",
    "\n",
    "    user_features_np = user_features.to_numpy()\n",
    "    movie_features_np = movie_features.to_numpy()\n",
    "\n",
    "    user_id_map = create_id_mappings(user_features.index)\n",
    "    movie_id_map = create_id_mappings(movie_features.index)\n",
    "\n",
    "    for user1_id, user_movies in interaction_matrix.iterrows():\n",
    "        rated_movies = user_movies[user_movies > 0].index\n",
    "        if rated_movies.empty:\n",
    "            continue\n",
    "\n",
    "        user1_idx = user_id_map[user1_id]\n",
    "        user1_features = user_features_np[user1_idx]\n",
    "\n",
    "        for movie_id in rated_movies:\n",
    "            if movie_id not in movie_id_map:\n",
    "                continue\n",
    "            movie_idx = movie_id_map[movie_id]\n",
    "            movie_features = movie_features_np[movie_idx]\n",
    "            other_users = interaction_matrix.index[interaction_matrix[movie_id] > 0].difference([user1_id])\n",
    "\n",
    "            for user2_id in other_users:\n",
    "                if user2_id not in user_id_map:\n",
    "                    continue\n",
    "                user2_idx = user_id_map[user2_id]\n",
    "\n",
    "                # Ensure unique pairs by ordering the user IDs\n",
    "                if user1_id < user2_id:\n",
    "                    user2_features = user_features_np[user2_idx]\n",
    "                    avg_rating = (interaction_matrix.at[user1_id, movie_id] + interaction_matrix.at[user2_id, movie_id]) / 2\n",
    "\n",
    "                    user1_vecs.append(user1_features)\n",
    "                    user2_vecs.append(user2_features)\n",
    "                    movie_vecs.append(movie_features)\n",
    "                    ratings.append(avg_rating)\n",
    "\n",
    "    return (np.array(user1_vecs), np.array(user2_vecs), np.array(movie_vecs), np.array(ratings))\n",
    "\n",
    "user1_vecs, user2_vecs, movie_vecs, ratings = create_dataset(user_features, movie_features, Y.loc[Y.index[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "users = np.concatenate([user1_vecs, user2_vecs])\n",
    "scalerUsers = StandardScaler()\n",
    "scalerUsers.fit(users)\n",
    "user1_vecs = scalerUsers.transform(user1_vecs)\n",
    "user2_vecs = scalerUsers.transform(user2_vecs)\n",
    "\n",
    "scalerMovies = StandardScaler()\n",
    "scalerMovies.fit(movie_vecs)\n",
    "movie_vecs = scalerMovies.transform(movie_vecs)\n",
    "\n",
    "scalerRatings = MinMaxScaler((-1, 1))\n",
    "scalerRatings.fit(ratings.reshape(-1, 1))\n",
    "ratings = scalerRatings.transform(ratings.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.concatenate([user1_vecs, user2_vecs, movie_vecs], axis=1)\n",
    "y = ratings\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user1_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user2_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,424</span> │ user1_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │ user2_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">53,664</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,168</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user1_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user2_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m43,424\u001b[0m │ user1_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │ user2_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m53,664\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m43,168\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,256</span> (547.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140,256\u001b[0m (547.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,256</span> (547.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140,256\u001b[0m (547.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "tf.random.set_seed(42)\n",
    "user_NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='relu')\n",
    "])\n",
    "\n",
    "combined_NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='relu')\n",
    "])\n",
    "\n",
    "movie_NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation='relu')\n",
    "])\n",
    "\n",
    "user1_input = tf.keras.layers.Input(shape=(user_features.shape[1],), name='user1_input')\n",
    "user2_input = tf.keras.layers.Input(shape=(user_features.shape[1],), name='user2_input')\n",
    "movie_input = tf.keras.layers.Input(shape=(movie_features.shape[1],), name='movie_input')\n",
    "\n",
    "v_user1 = user_NN(user1_input)\n",
    "v_user1 = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(v_user1)\n",
    "\n",
    "v_user2 = user_NN(user2_input)\n",
    "v_user2 = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(v_user2)\n",
    "\n",
    "combined_user = tf.keras.layers.concatenate([v_user1, v_user2])\n",
    "v_combined = combined_NN(combined_user)\n",
    "v_combined = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(v_combined)\n",
    "\n",
    "v_movie = movie_NN(movie_input)\n",
    "v_movie = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x, axis=1))(v_movie)\n",
    "\n",
    "rating = tf.keras.layers.Dot(axes=1)([v_combined, v_movie])\n",
    "\n",
    "model = tf.keras.Model(inputs=[user1_input, user2_input, movie_input], outputs=rating)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer=opt, loss=loss_fn)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m19243/19243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4ms/step - loss: 0.1095 - val_loss: 0.0995\n",
      "Epoch 2/2\n",
      "\u001b[1m19243/19243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 0.0987 - val_loss: 0.0964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x39a66ed50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'user1_input': X_train[:, :user_features.shape[1]], 'user2_input': X_train[:, user_features.shape[1]:2*user_features.shape[1]], 'movie_input': X_train[:, 2*user_features.shape[1]:]},\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48107/48107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 449us/step - loss: 0.0963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09652964025735855"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.evaluate(\n",
    "    {'user1_input': X_test[:, :user_features.shape[1]], 'user2_input': X_test[:, user_features.shape[1]:2*user_features.shape[1]], 'movie_input': X_test[:, 2*user_features.shape[1]:]},\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>seven samurai</td>\n",
       "      <td>Action|Drama</td>\n",
       "      <td>4.576725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>cinema paradiso</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>4.481499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>patton</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>4.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>chushingura</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.469363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>children of paradise</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>4.454284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>rebecca</td>\n",
       "      <td>Romance|Thriller</td>\n",
       "      <td>4.425601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>farewell my concubine</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>4.416856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>smashing time</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4.397852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>cold fever</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>4.397476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>sullivan's travels</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4.382164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title                genres    rating\n",
       "movieId                                                       \n",
       "2019             seven samurai          Action|Drama  4.576725\n",
       "1172           cinema paradiso  Comedy|Drama|Romance  4.481499\n",
       "1272                    patton             Drama|War  4.471500\n",
       "3092               chushingura                 Drama  4.469363\n",
       "2920      children of paradise         Drama|Romance  4.454284\n",
       "928                    rebecca      Romance|Thriller  4.425601\n",
       "446      farewell my concubine         Drama|Romance  4.416856\n",
       "3233             smashing time                Comedy  4.397852\n",
       "649                 cold fever          Comedy|Drama  4.397476\n",
       "2936        sullivan's travels                Comedy  4.382164"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unwatched_movies(user1, user2):\n",
    "    watched_movies = Y.loc[user1]\n",
    "    watched_movies = watched_movies[watched_movies > 0].index\n",
    "    watched_movies = watched_movies.union(Y.loc[user2][Y.loc[user2] > 0].index)\n",
    "    unwatched = movie_features[~movie_features.index.isin(watched_movies)]\n",
    "    return unwatched\n",
    "\n",
    "\n",
    "def recommend_movies(user1, user2, top_n=10):\n",
    "    unwatched = unwatched_movies(user1, user2)\n",
    "    user1_vec = user_features.loc[user1].to_numpy()\n",
    "    user2_vec = user_features.loc[user2].to_numpy()\n",
    "    user1_vec = scalerUsers.transform(user1_vec.reshape(1, -1))\n",
    "    user2_vec = scalerUsers.transform(user2_vec.reshape(1, -1))\n",
    "    user1_vec = user1_vec[0]\n",
    "    user2_vec = user2_vec[0]\n",
    "    user1_vec = user1_vec.reshape(1, -1)\n",
    "    user2_vec = user2_vec.reshape(1, -1)\n",
    "    user1_vec = np.repeat(user1_vec, unwatched.shape[0], axis=0)\n",
    "    user2_vec = np.repeat(user2_vec, unwatched.shape[0], axis=0)\n",
    "    movie_vec = scalerMovies.transform(unwatched.to_numpy())\n",
    "    rating = model.predict([user1_vec, user2_vec, movie_vec])\n",
    "    unwatched = movies_df.loc[unwatched.index]\n",
    "    unwatched['rating'] = scalerRatings.inverse_transform(rating)\n",
    "    return unwatched.sort_values('rating', ascending=False).head(top_n)\n",
    "\n",
    "\n",
    "recommend_movies(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  age  occupation zipcode\n",
       "userId                                \n",
       "1           F    1          10   48067\n",
       "2           M   56          16   70072\n",
       "3           M   25          15   55117\n",
       "4           M   45           7   02460\n",
       "5           M   25          20   55455\n",
       "...       ...  ...         ...     ...\n",
       "6036        F   25          15   32603\n",
       "6037        F   45           1   76006\n",
       "6038        F   56           1   14706\n",
       "6039        F   45           0   01060\n",
       "6040        M   25           6   11106\n",
       "\n",
       "[6040 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommander",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
